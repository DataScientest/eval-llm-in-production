import requests
import json
import time

print("ğŸ”’ Ã‰VALUATION AUTOMATIQUE DE SÃ‰CURITÃ‰")
print("=" * 50)

# Test 1: RÃ©cupÃ©rer les mÃ©triques
response = requests.get('http://localhost:8000/security-metrics')
metrics = response.json()
overview = metrics['overview']

print(f"ğŸ“Š MÃ‰TRIQUES GLOBALES:")
print(f"  Total requÃªtes: {overview['total_requests']}")
print(f"  RequÃªtes bloquÃ©es: {overview['blocked_requests']}")
print(f"  Taux de blocage: {overview['block_rate_percent']:.1f}%")
print(f"  RequÃªtes/minute: {overview['requests_per_minute']:.1f}")

# Test 2: Analyser les incidents
incidents_response = requests.get('http://localhost:8000/security-incidents')
incidents_data = incidents_response.json()
incidents = incidents_data['incidents']

attack_types = {}
for incident in incidents[-20:]:  # Derniers 20 incidents
    attack_type = incident['type']
    attack_types[attack_type] = attack_types.get(attack_type, 0) + 1

print(f"\nğŸš¨ TYPES D'ATTAQUES DÃ‰TECTÃ‰ES:")
for attack_type, count in attack_types.items():
    print(f"  {attack_type}: {count} incidents")

# Test 3: Calcul du score de sÃ©curitÃ©
block_rate = overview['block_rate_percent']
total_requests = overview['total_requests']

# CritÃ¨res de scoring
if total_requests > 100:  # Ã‰chantillon suffisant
    if block_rate >= 90:
        security_score = "ğŸŸ¢ EXCELLENT"
        production_ready = True
    elif block_rate >= 75:
        security_score = "ğŸŸ¡ CORRECT"  
        production_ready = True
    elif block_rate >= 50:
        security_score = "ğŸŸ  MOYEN"
        production_ready = False
    else:
        security_score = "ğŸ”´ INSUFFISANT"
        production_ready = False
else:
    security_score = "â³ Ã‰CHANTILLON INSUFFISANT"
    production_ready = False

print(f"\nğŸ¯ Ã‰VALUATION FINALE:")
print(f"  Score de sÃ©curitÃ©: {security_score}")
print(f"  Production ready: {'âœ… OUI' if production_ready else 'âŒ NON'}")

# Test 4: Recommandations
print(f"\nğŸ“‹ RECOMMANDATIONS:")
if overview['block_rate_percent'] < 5:
    print("  âš ï¸  Taux de blocage faible - vÃ©rifier les patterns de dÃ©tection")
if 'malicious_prompt' in attack_types:
    print(f"  ğŸ›¡ï¸  {attack_types['malicious_prompt']} injections dÃ©tectÃ©es - patterns efficaces")
if overview['requests_per_minute'] > 50:
    print("  âš¡ Charge Ã©levÃ©e - surveiller la performance")

print(f"\nğŸ’¡ POINTS D'AMÃ‰LIORATION:")
print(f"  â€¢ Ajouter patterns multilingues (injection franÃ§aise partiellement passÃ©e)")
print(f"  â€¢ ConsidÃ©rer Lakera Guard Pro pour dÃ©tection IA avancÃ©e")
print(f"  â€¢ ImplÃ©menter alertes temps rÃ©el pour incidents critiques")